## Repository Contents
- `createDataset.py` – Downloads CIFAR-10 (500 train / 100 test samples per class), extracts 512-dim ResNet-18 features, applies PCA to 50 dimensions, and saves `{X,Y}_{train,test}` NumPy arrays under `processed_data/`.
- `GaussianNaiveBayes.py` – Custom Gaussian Naive Bayes implementation that estimates per-class means, variances, and priors.
- `SklearnNaiveBayes.py` – Convenience wrapper around `sklearn.naive_bayes.GaussianNB`.
- `evaluateNaiveBayes.py` – Shared evaluation helper printing accuracy, weighted precision/recall/F1, and confusion matrix.
- `runNaiveBayes.py` – Loads PCA features and evaluates both the custom and sklearn Naive Bayes models.
- `DecisionTreeScratch.py` – Decision Tree classifier implemented from scratch using Gini impurity.
- `SklearnDecisionTree.py` – Wrapper that trains a `sklearn.tree.DecisionTreeClassifier`.
- `runDecisionTree.py` – Compares sklearn vs. scratch Decision Trees on the PCA features and prints detailed metrics.
- `MLP.py` – Defines five fully connected architectures (base/deep/shallow/small-hidden/large-hidden) plus utilities to train, predict, and build PyTorch `DataLoader`s from the PCA data.
- `runMLP.py` – Trains every MLP variant, saves checkpoints into `models/`, and prints evaluation metrics.
- `evaluateMLP.py` – Reloads previously trained MLP checkpoints and reevaluates them without retraining.
- `CNN_VGG11.py` – Contains three VGG11-style CNN variants (baseline, deeper, kernel-size 5).
- `runCNN.py` – Trains a selected CNN variant directly on CIFAR-10 images (same per-class sampling as preprocessing) and saves the best/last checkpoints.
- `evaluateCNN.py` – Loads a saved CNN checkpoint, computes macro/per-class metrics, and stores the confusion matrix + summary in `models/`.
- `models/` – Checkpoints and metric artifacts written by MLP and CNN scripts (created automatically).
- `processed_data/` – PCA feature arrays generated by `createDataset.py`.
- `data/` – Torchvision-managed CIFAR-10 cache (downloaded automatically when needed).

## Data Pre-processing Workflow
Run the preprocessing script once to populate `processed_data/` with PCA features:
```bash
python createDataset.py
```
This script will:
1. Download CIFAR-10 with normalization/resizing suitable for ResNet-18 feature extraction.
2. Select the first 500 training and 100 test images for each of the 10 classes (balanced subset).
3. Extract 512-dimensional features using a frozen pretrained ResNet-18 (final pooling output).
4. Fit PCA on the training features (50 components) and transform both train/test splits.
5. Save `X_train_pca.npy`, `Y_train.npy`, `X_test_pca.npy`, `Y_test.npy` under `processed_data/`.

You must retun this script if you delete `processed_data/` or want a fresh dataset.

## Training and Evaluation Instructions

### Gaussian Naive Bayes
Train/evaluate both custom and sklearn implementations on the PCA features:
```bash
python runNaiveBayes.py
```
Outputs include accuracy, weighted precision/recall/F1, and confusion matrices for each model.

### Decision Trees
Compare sklearn vs. scratch classifier:
```bash
python runDecisionTree.py
```
Metrics (accuracy, classification report, confusion matrix) for both models are printed to the console.

### Multi-Layer Perceptrons (MLP)
1. **Training all variants:**
   ```bash
   python runMLP.py
   ```
   - Uses PCA features.
   - Trains the five architectures sequentially for 50 epochs each.
   - Saves checkpoints to `models/mlp_*.pth`.
   - Prints evaluation metrics immediately after each training run.
2. **Evaluating saved variants (no retraining):**
   ```bash
   python evaluateMLP.py
   ```
   Ensures the `models/` directory contains the checkpoints produced earlier.

### Convolutional Neural Networks (CNN)
CNN workflows operate directly on CIFAR-10 images.

1. **Training** (choose variant via `MODEL_NAME` at the top of `runCNN.py`; valid options: `baseline`, `deeper`, `kernel5`):
   ```bash
   python runCNN.py
   ```
   - Downloads CIFAR-10 if needed.
   - Uses the same per-class sample counts as preprocessing (500 train / 100 test) for fair comparison.
   - Saves best and last checkpoints to `models/cnn_<variant>_{best,last}.pth`.
2. **Evaluation** (pass the variant name on the command line):
   ```bash
   python evaluateCNN.py <MODEL_NAME>
   ```
   - Loads `models/cnn_kernel5_best.pth`.
   - Computes accuracy, macro precision/recall/F1, per-class metrics, and confusion matrix.
   - Saves metrics to `models/cnn_<variant>_metrics.txt` and confusion matrix to `models/cnn_<variant>_confusion.npy`.

## Applying Models
- **Classical models (Naive Bayes / Decision Trees / MLPs):** Predictions on the held-out PCA test set are produced within their respective run scripts. To adapt them for new data, ensure you pass PCA-compressed features consistent with `createDataset.py` (i.e., same PCA model).
- **CNNs:** Use `evaluateCNN.py` to generate predictions on the balanced CIFAR-10 test subset. For other datasets, adapt `get_limited_indices_by_class` and transforms as needed, keeping the class ordering consistent.
